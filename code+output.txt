> library(rpart)
> library(lattice)
> library(ggplot2)
> library(caret)
> library(corrplot)
> library(caTools)
> library(rpart.plot)
> library(randomForest)
> library(DMwR) 
> library(gridExtra)
> 
> setwd("C:/Users/SB052807/Desktop/AI/DataSet-Diabetes/")
> problem4_diabetes <- read.csv("problem4_diabetes.csv")
> 
> # Create training and testing set
> 
> set.seed(12345)
> ratio = sample(1:nrow(problem4_diabetes), size = 0.30*nrow(problem4_diabetes))
> testing_diabetes = problem4_diabetes[ratio,] #Test dataset 30% of total
> training_diabetes = problem4_diabetes[-ratio,] #Train dataset 70% of total
> 
> ## Dealing with zeros
> missing_data <- problem4_diabetes[,setdiff(names(problem4_diabetes), c('Outcome', 'Pregnancies'))]
> features_miss_num <- apply(missing_data, 2, function(x) sum(x <= 0))
> features_miss <- names(missing_data)[ features_miss_num > 0]
> 
> rows_miss <- apply(missing_data, 1, function(x) sum(x <= 0) >= 1) 
> sum(rows_miss)
[1] 376
> 
> missing_data[missing_data <= 0] <- NA
> problem4_diabetes[, names(missing_data)] <- missing_data
> 
> #Data Pre-Processing
> 
> colSums(is.na(problem4_diabetes))#Checking for invalid data
             Pregnancies                  Glucose            BloodPressure            SkinThickness                  Insulin 
                       1                        5                       35                      227                      374 
                     BMI DiabetesPedigreeFunction                      Age                  Outcome 
                      11                        0                        0                        0 
> 
> #Since Skin Thickness and Glucose had 227 and 374 zero-values respectively 
> # KNN imputation
> #So performing knn Imputation to correct the zero values.
> problem4_diabetes[,c(-8,-9)] <- knnImputation(problem4_diabetes[,c(-8,-9)], k = 5)
> colSums(is.na(problem4_diabetes))#Checking for invalid data
             Pregnancies                  Glucose            BloodPressure            SkinThickness                  Insulin 
                       0                        0                        0                        0                        0 
                     BMI DiabetesPedigreeFunction                      Age                  Outcome 
                       0                        0                        0                        0 
> 
> #Plotting the features against Outcome
> 
> p2 <- ggplot(problem4_diabetes, aes(x = Glucose, color = Outcome, fill = as.factor(Outcome))) + geom_density(alpha = 0.8) + theme(legend.position = "bottom") +labs(x = "Glucose", y = "Density", title = "Density plot of glucose")
> p1 <- ggplot(problem4_diabetes, aes(x = Outcome, y = Glucose,fill = as.factor(Outcome))) + geom_boxplot() + theme(legend.position = "bottom") + ggtitle("Variation of glucose Vs Diabetes")
> 
> gridExtra::grid.arrange(p1,p2, ncol=2)
> 
> p4 <- ggplot(problem4_diabetes, aes(x = BloodPressure, color = Outcome, fill = as.factor(Outcome))) + geom_density(alpha = 0.8) + theme(legend.position = "bottom") +labs(x = "BloodPressure", y = "Density", title = "Density plot of BloodPressure")
> p3 <- ggplot(problem4_diabetes, aes(x = Outcome, y = BloodPressure,fill = as.factor(Outcome))) + geom_boxplot() + theme(legend.position = "bottom") + ggtitle("Variation of BloodPressure Vs Diabetes")
> 
> gridExtra::grid.arrange(p3,p4, ncol=2)
> 
> 
> #Correlation Graph
> 
> corMat = cor (problem4_diabetes[, -9])
> diag (corMat) = 0 #Remove self correlations
> corrplot.mixed(corMat,tl.pos = "lt") 
> 
> 
> # MODEL- Logistic Regression Model(GLM)
> 
> diabetes_glm_model <- glm (Outcome ~ ., data = training_diabetes, family = binomial)
> step_model <- step(diabetes_glm_model) 
Start:  AIC=542.06
Outcome ~ Pregnancies + Glucose + BloodPressure + SkinThickness + 
    Insulin + BMI + DiabetesPedigreeFunction + Age

                           Df Deviance    AIC
- SkinThickness             1   524.28 540.28
- Insulin                   1   524.59 540.59
<none>                          524.06 542.06
- Age                       1   526.21 542.21
- DiabetesPedigreeFunction  1   528.50 544.50
- BloodPressure             1   528.66 544.66
- Pregnancies               1   532.55 548.55
- BMI                       1   568.50 584.50
- Glucose                   1   598.96 614.96

Step:  AIC=540.28
Outcome ~ Pregnancies + Glucose + BloodPressure + Insulin + BMI + 
    DiabetesPedigreeFunction + Age

                           Df Deviance    AIC
- Insulin                   1   525.40 539.40
<none>                          524.28 540.28
- Age                       1   526.65 540.65
- DiabetesPedigreeFunction  1   528.59 542.59
- BloodPressure             1   529.40 543.40
- Pregnancies               1   532.73 546.73
- BMI                       1   571.20 585.20
- Glucose                   1   602.33 616.33

Step:  AIC=539.4
Outcome ~ Pregnancies + Glucose + BloodPressure + BMI + DiabetesPedigreeFunction + 
    Age

                           Df Deviance    AIC
<none>                          525.40 539.40
- Age                       1   528.10 540.10
- DiabetesPedigreeFunction  1   529.20 541.20
- BloodPressure             1   530.77 542.77
- Pregnancies               1   534.05 546.05
- BMI                       1   571.29 583.29
- Glucose                   1   605.59 617.59
> 
> #glm model with the lowest AIC value 
> #diabetes_glm_model_final <- glm (Outcome ~ Pregnancies + Glucose + BMI + DiabetesPedigreeFunction, data = training_diabetes, family = binomial)
> 
> #Prediction 
> 
> diabetes_predicted <- predict(diabetes_glm_model,testing_diabetes, type="response")
> rounded_diabetes_predicted<-round(diabetes_predicted)
> 
> #Confusion Matrix
> 
> cm_glm<-confusionMatrix(rounded_diabetes_predicted,testing_diabetes$Outcome )
> print(cm_glm)
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 142  26
         1  19  43
                                          
               Accuracy : 0.8043          
                 95% CI : (0.7471, 0.8536)
    No Information Rate : 0.7             
    P-Value [Acc > NIR] : 0.0002262       
                                          
                  Kappa : 0.5203          
 Mcnemar's Test P-Value : 0.3710934       
                                          
            Sensitivity : 0.8820          
            Specificity : 0.6232          
         Pos Pred Value : 0.8452          
         Neg Pred Value : 0.6935          
             Prevalence : 0.7000          
         Detection Rate : 0.6174          
   Detection Prevalence : 0.7304          
      Balanced Accuracy : 0.7526          
                                          
       'Positive' Class : 0               
                                          
> 
> 
> # MODEL- Random Forest
> 
> diabetes_model_RandomForest <- randomForest(Outcome ~ .,data=training_diabetes,importance =TRUE)
> 
> #Prediction
> diabetes_predicted_rf<-predict(diabetes_model_RandomForest,testing_diabetes,type ="class")
> rounded_diabetes_predicted_rf<-round(diabetes_predicted_rf)
> 
> #Confusion Matrix
> cm_rf <- confusionMatrix(rounded_diabetes_predicted_rf,testing_diabetes$Outcome)
> print(cm_rf)
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 156   5
         1   5  64
                                         
               Accuracy : 0.9565         
                 95% CI : (0.9215, 0.979)
    No Information Rate : 0.7            
    P-Value [Acc > NIR] : <2e-16         
                                         
                  Kappa : 0.8965         
 Mcnemar's Test P-Value : 1              
                                         
            Sensitivity : 0.9689         
            Specificity : 0.9275         
         Pos Pred Value : 0.9689         
         Neg Pred Value : 0.9275         
             Prevalence : 0.7000         
         Detection Rate : 0.6783         
   Detection Prevalence : 0.7000         
      Balanced Accuracy : 0.9482         
                                         
       'Positive' Class : 0              
                                         
> 
> # MODEL- Decision Tree
> 
> diabetes_model_DecisionTree <- rpart(Outcome~., data=training_diabetes, method="class")
> rpart.plot(diabetes_model_DecisionTree)
> 
> #Prediction
> diabetes_predicted_DT<- predict(diabetes_model_DecisionTree, testing_diabetes, type = "class")
> 
> #CONFUSION MATRIX
> 
> cm_dt <- confusionMatrix(diabetes_predicted_DT,testing_diabetes$Outcome)
> print(cm_dt)
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 129  17
         1  32  52
                                         
               Accuracy : 0.787          
                 95% CI : (0.7283, 0.838)
    No Information Rate : 0.7            
    P-Value [Acc > NIR] : 0.001953       
                                         
                  Kappa : 0.5224         
 Mcnemar's Test P-Value : 0.045500       
                                         
            Sensitivity : 0.8012         
            Specificity : 0.7536         
         Pos Pred Value : 0.8836         
         Neg Pred Value : 0.6190         
             Prevalence : 0.7000         
         Detection Rate : 0.5609         
   Detection Prevalence : 0.6348         
      Balanced Accuracy : 0.7774         
                                         
       'Positive' Class : 0              
                                         

